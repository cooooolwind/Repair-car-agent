import gradio as gr
import agent_backend as backend
import os

# --- CSS æ ·å¼ ---
custom_css = """
.gradio-container { background-color: white !important; }
footer {display: none !important;}
.bubble-wrap { background-color: #f9f9f9; border-radius: 12px; }

#input-card-group {
    background: white;
    border-radius: 24px !important;
    box-shadow: 0 8px 30px rgba(0, 0, 0, 0.08) !important;
    border: 1px solid rgba(0, 0, 0, 0.03) !important;
    padding: 10px !important;
    margin-top: 20px;
    transition: box-shadow 0.3s ease;
}
#input-card-group:hover { box-shadow: 0 12px 40px rgba(0, 0, 0, 0.12) !important; }

#chat-input textarea {
    background-color: transparent !important;
    border: none !important;
    box-shadow: none !important;
    font-size: 16px !important;
}
#chat-input { background-color: transparent !important; border: none !important; }
.upload-button { background-color: transparent !important; border: none !important; }
"""

# --- å¤„ç†å‡½æ•° (å¢åŠ  state å‚æ•°) ---
def agent_response(user_input, history, state):
    """
    state: è¿™æ˜¯ gr.State å¯¹è±¡ï¼Œå­˜å‚¨åç«¯çš„ messages åˆ—è¡¨
    """
    if user_input is None: user_input = {}
    text = user_input.get("text", "")
    files = user_input.get("files", [])
    
    raw_file_path = files[0] if files else None
    
    # PDF/å›¾ç‰‡å¤„ç†
    final_image_paths = []
    
    if raw_file_path:
        file_ext = os.path.splitext(raw_file_path)[1].lower()
        if file_ext == '.pdf':
            converted_paths = backend.convert_pdf_to_image(raw_file_path)
            if converted_paths:
                final_image_paths = converted_paths
                if not text: text = "è¯·åˆ†æè¿™ä»½æ–‡æ¡£çš„å†…å®¹ã€‚"
        else:
            final_image_paths = [raw_file_path]

    if history is None: history = []
        
    # --- ğŸ‘‡ è¿™é‡Œæ˜¯ä¿®æ”¹åçš„éƒ¨åˆ† ğŸ‘‡ ---
    is_pdf = raw_file_path and raw_file_path.lower().endswith('.pdf')

    if final_image_paths:
        if is_pdf:
            # PDF æ¨¡å¼ï¼šä»…æ˜¾ç¤ºæ–‡å­—ï¼Œéšè—å›¾ç‰‡
            display_content = text if text else f"ğŸ“„ å·²æ¥æ”¶ PDF æ–‡æ¡£ ({len(final_image_paths)} é¡µ)"
            history.append({"role": "user", "content": display_content})
        else:
            # å›¾ç‰‡æ¨¡å¼ï¼šæ˜¾ç¤ºå›¾ç‰‡å’Œæ–‡å­—
            for img_path in final_image_paths:
                history.append({"role": "user", "content": f"![]({img_path})"})
            if text: 
                history.append({"role": "user", "content": text})
    elif text:
        history.append({"role": "user", "content": text})
    # --- ğŸ‘† ä¿®æ”¹ç»“æŸ ğŸ‘† ---
    
    history.append({"role": "assistant", "content": "ğŸ¤– Agent æ­£åœ¨å¯åŠ¨..."})
    
    
    full_process_log = ""
    final_answer = ""
    prompt_text = text if text else ("è¯·åˆ†æè¿™äº›å›¾ç‰‡å¹¶æ‰§è¡Œæ“ä½œã€‚" if final_image_paths else "")
    
    if not prompt_text:
        yield history, None, full_process_log, gr.update(visible=True), state
        return

    # --- ğŸŒŸ è°ƒç”¨åç«¯ (ä¼ å…¥ state) ---
    # æ³¨æ„ï¼šå¦‚æœ state æ˜¯ Noneï¼Œåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
    current_backend_history = state if state is not None else []
    
    generator = backend.run_agent(prompt_text, final_image_paths, current_backend_history)
    
    status_display = "ğŸ¤– æ­£åœ¨å¤„ç†ä¸­..." 
    
    # ğŸŒŸ ä¸´æ—¶å˜é‡ï¼Œç”¨äºæ¥æ”¶åç«¯è¿”å›çš„æ–°çŠ¶æ€
    new_backend_history = current_backend_history 
    
    for step in generator:
        step_type = step.get("type")
        content = step.get("content")
        
        if step_type == "thought":
            status_display = "ğŸ§  æ­£åœ¨æ€è€ƒä¸‹ä¸€æ­¥..."
            full_process_log += f"ğŸ§  **æ€è€ƒ**: {content}\n\n"
        elif step_type == "tool_start":
            tool_name = content.split('(')[0] if '(' in content else content
            status_display = f"ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}..."
            full_process_log += f"ğŸ› ï¸ **å·¥å…·**: `{content}`\n\n"
        elif step_type == "observation":
            status_display = "ğŸ‘€ æ­£åœ¨åˆ†æç»“æœ..."
            full_process_log += f"ğŸ‘€ **è§‚å¯Ÿ**:\n{content}\n\n"
        elif step_type == "result":
            final_answer = content
            full_process_log += f"âœ… **ç»“æœ**: {content}\n\n"
        
        # ğŸŒŸ ç›‘å¬çŠ¶æ€æ›´æ–°äº‹ä»¶
        elif step_type == "update_state":
            new_backend_history = content # æ‹¿åˆ°åç«¯æ•´ç†å¥½çš„æ–°å†å²
            # ä¸æŠŠè¿™ä¸ªæ˜¾ç¤ºåœ¨æ—¥å¿—é‡Œ

        # æ›´æ–° UI
        if final_answer:
            history[-1]["content"] = final_answer
        else:
            history[-1]["content"] = status_display
        
        # ğŸŒŸ Yield å¿…é¡»åŒ…å« state (ä½œä¸ºç¬¬5ä¸ªè¿”å›å€¼)
        yield history, None, full_process_log, gr.update(visible=True), new_backend_history


# --- æ„å»ºç•Œé¢ ---
with gr.Blocks(title="æ™ºèƒ½ä¿®è½¦åŠ©æ‰‹") as demo:
    
    # ğŸŒŸ 1. å®šä¹‰çŠ¶æ€å­˜å‚¨ç»„ä»¶ (ä¸å¯è§)
    backend_state = gr.State([]) 

    with gr.Column(elem_id="main-container"):
        gr.HTML("""
        <div style="text-align: center; margin-top: 40px; margin-bottom: 20px;">
            <div style="display: flex; align-items: center; justify-content: center; gap: 10px; color: #4e6af3; margin-bottom: 10px;">
                <svg width="30" height="30" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-1 17.93c-3.95-.49-7-3.85-7-7.93 0-.62.08-1.21.21-1.79L9 15v1c0 1.1.9 2 2 2v1.93zm6.9-2.54c-.26-.81-1-1.39-1.9-1.39h-1v-3c0-.55-.45-1-1-1H8v-2h2c.55 0 1-.45 1-1V7h2c1.1 0 2-.9 2-2v-.41c2.93 1.19 5 4.06 5 7.41 0 2.08-.8 3.97-2.1 5.39z"/></svg>
                <span style="font-weight: 500; font-size: 1.2rem;">CarRepair Agent</span>
            </div>
            <h1 style="font-size: 2rem; font-weight: 700; color: #333;">ä»Šå¤©æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ ï¼Ÿ</h1>
        </div>
        """)

    chatbot = gr.Chatbot(
        label="", 
        show_label=False,
        height=400,
        avatar_images=(None, "https://img.icons8.com/color/48/robot-2.png"),
        elem_id="chatbot"
    )

    with gr.Group(elem_id="input-card-group"):
        with gr.Row(equal_height=True):
            chat_input = gr.MultimodalTextbox(
                elem_id="chat-input",
                interactive=True,
                file_types=["image", ".pdf"],
                placeholder="è¾“å…¥æŒ‡ä»¤æˆ–ä¸Šä¼ ç…§ç‰‡/PDFæ‰‹å†Œ...",
                show_label=False,
                scale=9, 
                container=False 
            )
            
    with gr.Accordion("ğŸ§  æ€è€ƒè¿‡ç¨‹", open=False, visible=False) as process_acc:
        process_display = gr.Markdown("...")

    # ğŸŒŸ ç»‘å®šäº‹ä»¶ï¼šå¢åŠ äº† backend_state çš„è¾“å…¥å’Œè¾“å‡º
    chat_input.submit(
        fn=agent_response, 
        inputs=[chat_input, chatbot, backend_state], # è¾“å…¥ state
        outputs=[chatbot, chat_input, process_display, process_acc, backend_state] # è¾“å‡ºæ›´æ–°åçš„ state
    )

# --- agent_gradio.py åº•éƒ¨ä¿®æ”¹ ---

if __name__ == "__main__":
    # ç¡®ä¿ image æ–‡ä»¶å¤¹å­˜åœ¨ï¼ˆé˜²æ­¢åˆšå¯åŠ¨æ—¶æŠ¥é”™ï¼‰
    if not os.path.exists("image"):
        os.makedirs("image")

    demo.queue().launch(
        server_name="127.0.0.1", 
        server_port=6006,
        css=custom_css,          
        theme=gr.themes.Soft(),
        # ğŸŒŸ å…³é”®ä¿®æ”¹ï¼šå…è®¸è®¿é—® image æ–‡ä»¶å¤¹
        allowed_paths=["./image"] 
    )