import re
from openai import OpenAI
import os
import base64
from pdf2image import convert_from_path

# --- é…ç½® ---
# âš ï¸âš ï¸âš ï¸ è¯·ç¡®ä¿ä½ çš„ API Key æ­£ç¡®
API_KEY = "sk-5eb60c1091ba459aa9246ea714db371c" 
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"

# ğŸŒŸ æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨è§†è§‰æ¨¡å‹ Qwen-VL
MODEL_ID = "qwen3-vl-plus" 

AGENT_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä¿®è½¦æ‹§èºä¸åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼ˆå¯èƒ½åŒ…å«å›¾ç‰‡å’Œpdfï¼‰ï¼Œå¹¶ä½¿ç”¨å¯ç”¨å·¥å…·ä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚

# å¯ç”¨å·¥å…·:
- `get_point()`: æ¨¡æ‹Ÿè§†è§‰ç³»ç»Ÿï¼Œè¿”å›èºä¸çš„åæ ‡ã€‚
- `Arm_move(x: int, y: int)`: ç§»åŠ¨æœºæ¢°è‡‚åˆ°æŒ‡å®šä½ç½®ã€‚
- `Hand_move(type: str)`: ç§»åŠ¨æœºæ¢°æ‰‹ï¼Œtype=â€˜1â€™è¡¨ç¤ºå‘ä¸Šæ‹§ç´§ï¼Œtype=â€˜0â€™è¡¨ç¤ºå‘ä¸‹æ‹§æ¾ã€‚

# è¡ŒåŠ¨æ ¼å¼:
ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚é¦–å…ˆæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åæ˜¯ä½ è¦æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨ï¼Œæ¯æ¬¡å›å¤åªè¾“å‡ºä¸€å¯¹Thought-Actionï¼š
Thought: [è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œä¸‹ä¸€æ­¥è®¡åˆ’]
Action: ä½ å†³å®šé‡‡å–çš„è¡ŒåŠ¨ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€:
- `function_name(arg_name="arg_value")`:è°ƒç”¨ä¸€ä¸ªå¯ç”¨å·¥å…·ã€‚
- `Finish[æœ€ç»ˆç­”æ¡ˆ]`:å½“ä½ è®¤ä¸ºå·²ç»è·å¾—æœ€ç»ˆç­”æ¡ˆæ—¶ã€‚
- å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨Action:å­—æ®µåä½¿ç”¨ Finish[æœ€ç»ˆç­”æ¡ˆ] æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

è¯·å¼€å§‹å§ï¼
"""

# --- å·¥å…·å‡½æ•° ---
def get_point() -> str:
    return "ç³»ç»Ÿå®šä½åé¦ˆï¼šåœ¨åæ ‡ (X:200, Y:150) å¤„å‘ç°å¾…å¤„ç†èºä¸å­”ä½ã€‚"


def Arm_move(x,y) -> str:
    x,y=200,150
    return "å·²ç§»åŠ¨æœºæ¢°è‡‚åˆ°æŒ‡å®šä½ç½®ã€‚"

def Hand_move(type: str) -> str:
    val = str(type).strip()
    if val == "1":
        return "æœºæ¢°æ‰‹çŠ¶æ€ï¼šå·²å‘ä¸Šç§»åŠ¨å¹¶æ‹§ç´§ã€‚"
    elif val == "0":
        return "æœºæ¢°æ‰‹çŠ¶æ€ï¼šå·²å‘ä¸‹ç§»åŠ¨å½’ä½ã€‚"
    else:
        return f"é”™è¯¯ï¼šæœªçŸ¥ç±»å‹ {type}ã€‚"

available_tools = {
    "get_point": get_point,
    "Arm_move": Arm_move,
    "Hand_move": Hand_move, 
}
# --- æ–°å¢ï¼šPDF è½¬å›¾ç‰‡è¾…åŠ©å‡½æ•° ---
def convert_pdf_to_image(pdf_path):
    """
    å°† PDF çš„æ‰€æœ‰é¡µé¢è½¬æ¢ä¸ºå›¾ç‰‡ï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ° image æ–‡ä»¶å¤¹
    """
    try:
        # 1. å®šä¹‰ä¿å­˜ç›®å½•
        save_dir = "image"
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)  # å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨åˆ›å»º

        # è½¬æ¢ PDF
        images = convert_from_path(pdf_path)
        
        saved_paths = []
        if images:
            # è·å– PDF çš„æ–‡ä»¶åï¼ˆä¸å¸¦è·¯å¾„å’Œåç¼€ï¼‰ï¼Œç”¨äºç»™å›¾ç‰‡å‘½å
            # ä¾‹å¦‚: /tmp/xxx/manual.pdf -> manual
            pdf_filename = os.path.basename(pdf_path)
            base_name = os.path.splitext(pdf_filename)[0]
            
            # å¾ªç¯ä¿å­˜æ¯ä¸€é¡µ
            for i, img in enumerate(images):
                # 2. æ‹¼æ¥ä¿å­˜è·¯å¾„: image/æ–‡ä»¶å_page_0.jpg
                image_filename = f"{base_name}_page_{i}.jpg"
                save_path = os.path.join(save_dir, image_filename)
                
                img.save(save_path, 'JPEG')
                saved_paths.append(save_path)
                
            print(f"ğŸ“„ PDF å·²è½¬æ¢ {len(saved_paths)} é¡µå›¾ç‰‡ï¼Œä¿å­˜åœ¨: {save_dir}")
            return saved_paths 
        else:
            return []
    except Exception as e:
        print(f"âŒ PDF è½¬æ¢å¤±è´¥: {e}")
        return []


# --- è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬ Base64 ---
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# --- LLM å®¢æˆ·ç«¯ ---
class OpenAICompatibleClient:
    def __init__(self, model, api_key, base_url):
        self.model = model
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def generate(self, messages):
        """
        ç›´æ¥æ¥æ”¶ messages åˆ—è¡¨ï¼Œæ”¯æŒå¤šæ¨¡æ€æ ¼å¼
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=False
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"LLM è°ƒç”¨é”™è¯¯: {e}"

llm = OpenAICompatibleClient(model=MODEL_ID, api_key=API_KEY, base_url=BASE_URL)

# --- æ ¸å¿ƒ Agent é€»è¾‘ ---
def run_agent(user_text, image_paths=None, history_state=None):
    """
    history_state: è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå­˜å‚¨äº†ä¹‹å‰è½®æ¬¡çš„ [UserMsg, AsstMsg, UserMsg, AsstMsg...]
    """
    # 1. å‡†å¤‡å›¾ç‰‡åˆ—è¡¨
    if image_paths:
        if isinstance(image_paths, str): target_images = [image_paths]
        elif isinstance(image_paths, list): target_images = image_paths
        else: target_images = []
    else:
        target_images = []

    # 2. æ„å»ºã€å½“å‰ã€‘ç”¨æˆ·çš„æ¶ˆæ¯å¯¹è±¡
    current_user_content = [{"type": "text", "text": user_text}]
    valid_image_count = 0
    for img_path in target_images:
        base64_image = encode_image(img_path)
        if base64_image:
            current_user_content.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
            })
            valid_image_count += 1
    
    current_user_message = {'role': 'user', 'content': current_user_content}
    
    yield {"type": "log", "content": f"æ”¶åˆ°è¯·æ±‚: {user_text} [å« {valid_image_count} å›¾]"}

    # 3. æ„å»ºã€å·¥ä½œè®°å¿†ã€‘(Working Memory)
    # å·¥ä½œè®°å¿† = System Prompt + å†å²è®°å¿† + å½“å‰ç”¨æˆ·æ¶ˆæ¯
    # æˆ‘ä»¬ä¸åœ¨ history_state é‡Œå­˜ System Promptï¼Œé˜²æ­¢é‡å¤
    
    if history_state is None:
        history_state = []
        
    # messages æ˜¯å‘ç»™å¤§æ¨¡å‹çš„å®Œæ•´åˆ—è¡¨
    messages = [{'role': 'system', 'content': AGENT_SYSTEM_PROMPT}] + history_state + [current_user_message]

    # 4. å¼€å§‹ ReAct å¾ªç¯
    final_answer = ""
    
    while True: 
        llm_output = llm.generate(messages)
        
        # æˆªæ–­å¤„ç†
        match = re.search(r'(Thought:.*?Action:.*?)(?=\n\s*(?:Thought:|Action:|Observation:)|\Z)', llm_output, re.DOTALL)
        if match: llm_output = match.group(1).strip()
            
        yield {"type": "thought", "content": llm_output}
        
        # å°†æ€è€ƒè¿‡ç¨‹åŠ å…¥ä¸´æ—¶ä¸Šä¸‹æ–‡ï¼Œè®©æ¨¡å‹çŸ¥é“è‡ªå·±åˆšæ‰æƒ³äº†ä»€ä¹ˆ
        messages.append({'role': 'assistant', 'content': llm_output})

        # è§£æ Finish
        finish_match = re.search(r"Finish\[(.*)\]", llm_output, re.DOTALL)
        if finish_match:
            final_answer = finish_match.group(1)
            yield {"type": "result", "content": final_answer}
            break

        # è§£æ Action
        action_match = re.search(r"Action: (.*)", llm_output, re.DOTALL)
        if not action_match:
            # æ²¡è§£æå‡ºActionï¼Œå¯èƒ½ç›´æ¥è¯´è¯äº†
            final_answer = llm_output
            yield {"type": "result", "content": final_answer} 
            break
            
        action_str = action_match.group(1).strip()
        
        if action_str.startswith("Finish"):
            final_answer = re.match(r"Finish\[(.*)\]", action_str).group(1)
            yield {"type": "result", "content": final_answer}
            break

        # æ‰§è¡Œå·¥å…·
        try:
            tool_name = re.search(r"(\w+)\(", action_str).group(1)
            args_content = re.search(r"\((.*)\)", action_str).group(1).strip()
            kwargs = {}
            if args_content:
                pairs = re.findall(r'(\w+)=["\']?([^"\',\s]+)["\']?', args_content)
                if pairs: kwargs = dict(pairs)
                elif tool_name == "Arm_move": kwargs = {"type": args_content}

            if tool_name in available_tools:
                observation = available_tools[tool_name](**kwargs)
            else:
                observation = f"é”™è¯¯: å·¥å…· '{tool_name}' ä¸å­˜åœ¨"
        except Exception as e:
            observation = f"æ‰§è¡Œé”™è¯¯: {e}"

        yield {"type": "observation", "content": observation}
        messages.append({'role': 'user', 'content': f"Observation: {observation}"})

    # 5. ä»»åŠ¡ç»“æŸï¼Œæ›´æ–°é•¿æœŸè®°å¿†
    # ä¸ºäº†èŠ‚çœ Tokenï¼Œæˆ‘ä»¬ä¸æŠŠä¸­é—´çš„ Thought/Observation å­˜å…¥é•¿æœŸè®°å¿†
    # æˆ‘ä»¬åªå­˜ï¼š1. ç”¨æˆ·åˆšæ‰è¯´çš„è¯ 2. Agent æœ€ç»ˆçš„å›ç­”
    
    if final_answer:
        new_history = history_state + [
            current_user_message,
            {'role': 'assistant', 'content': final_answer}
        ]
        # å‘é€ä¸€ä¸ªç‰¹æ®Šäº‹ä»¶ï¼Œé€šçŸ¥å‰ç«¯æ›´æ–°çŠ¶æ€
        yield {"type": "update_state", "content": new_history}